{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "M1,m2 = 0.2 , 0.034\n",
    "mean_interval,skew_interval,mean_overlap,skew_overlap = m2,0.14,m2/4,0.035\n",
    "var,var_no  =0.2,0.1 #variance for yes and no gaussian\n",
    "pos_th, en_th = 0.4, 11\n",
    "skew_change,mean_change = (skew_interval+2*skew_overlap)/10, (m2+2*mean_overlap)/10 #Change in mean and skew during a decision\n",
    "mn_max, sk_max = M1, 0 #initial values of mean and skew for apathy = 0\n",
    "w = 0.0005 #weighting on updating values in the learning process just /10\n",
    "en_max = 1.5\n",
    "neg_th = 0.7\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Defines the intervals the mean and skew are bound by when a decision is being made \n",
    "def interval(mean_interval,skew_interval,mean_overlap,skew_overlap,mn,sk,ap):\n",
    "    mean_min = mn-mean_interval-mean_overlap\n",
    "    mean_max = mn+mean_interval+mean_overlap\n",
    "    skew_min = sk-skew_interval-skew_overlap\n",
    "    skew_max = sk+skew_interval+skew_overlap\n",
    "    \n",
    "    return[mean_min,mean_max,skew_min,skew_max]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defines how the mean and skew will change during a decision, bound by the interval function \n",
    "def deliberation_no(mean_ap,skew_ap,intervals):\n",
    "    skew = skew_ap-skew_change\n",
    "    mean = mean_ap - mean_change\n",
    "\n",
    "    mins = [intervals[2],intervals[0]]\n",
    "    if skew< mins[0]:\n",
    "        skew = mins[0]\n",
    "    if mean < mins[1]:\n",
    "        mean=mins[1]\n",
    "    return [mean,skew]\n",
    "    \n",
    "def deliberation_yes(mean_ap,skew_ap,intervals):\n",
    "    skew = skew_ap + skew_change\n",
    "    mean = mean_ap + mean_change\n",
    "\n",
    "    maxs = [intervals[3],intervals[1]]\n",
    "    if skew>maxs[0]:\n",
    "        skew = maxs[0]\n",
    "    if mean > maxs[1]:\n",
    "        mean = maxs[1]\n",
    "    return [mean,skew]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defines the initial mean and skew for a given apathy to be used at the start of a simulation\n",
    "def initial(ap,mean_interval,skew_interval,mean_overlap,skew_overlap):\n",
    "    decimal = ap%1\n",
    "    ap = int(ap)\n",
    "    if ap>10 or ap<0:\n",
    "        return 'error'\n",
    "\n",
    "    \n",
    "    if ap !=0 and ap!=9 and ap!=10:\n",
    "        mn = mn_max +mean_overlap-(ap)*mean_interval - (mean_interval+2*mean_overlap)*decimal\n",
    "        sk = sk_max +  skew_overlap-(ap)*skew_interval - (skew_interval+2*mean_overlap)*decimal\n",
    "    \n",
    "    elif ap==9:\n",
    "        mn = mn_max - 10*mean_interval+(mean_interval+mean_overlap)*(1-decimal) \n",
    "        sk = sk_max-10*skew_interval + (skew_interval+skew_overlap)*(1-decimal)\n",
    "        \n",
    "    elif ap==0:\n",
    "        mn = mn_max - (mean_interval+mean_overlap)*decimal\n",
    "        sk = sk_max - (mean_interval+mean_overlap)*decimal\n",
    "\n",
    "    elif ap==10:\n",
    "        mn = mn_max - 10*mean_interval\n",
    "        sk = sk_max-10*skew_interval\n",
    "       \n",
    "    return [mn,sk]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Energy used per deliberation, or 0.25\n",
    "def en_ap(ap):\n",
    "    return (0.1+ap*0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The process of making a decision to engage or not by sampling under the gaussian\n",
    "# en is the energy usage\n",
    "#while loop ensures no value greater than 1 \n",
    "def decision_process(mean_ap,skew_ap,ap):\n",
    "  yes = no = 99\n",
    "  while yes>1 or no>1:\n",
    "    yes = stats.skewnorm.rvs(skew_ap,mean_ap,var)\n",
    "    no = np.random.normal(0,var_no)\n",
    "      \n",
    "    flg=0\n",
    "\n",
    "    val = abs(yes-no)\n",
    "    en = en_ap(ap)/val\n",
    "      \n",
    "    if en >en_max:\n",
    "      en = en_max\n",
    "    if yes>no:\n",
    "      flg=1\n",
    "\n",
    "    return [flg,val,en,yes,no]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one entire decision\n",
    "def one_decision(mn,sk,ap):\n",
    "    \n",
    "    rep = 0 #number of processes in the decision\n",
    "\n",
    "    pos = 0 #value assigned to engaging, if it reaches pos_th the decision is engage\n",
    "    neg = 0 #value of not engaging, if it reaches neg_th the decision is not engage\n",
    "    en = 0  #value of energy used, if it reaches en_th the decision is not engage\n",
    "\n",
    "    yes = 0 #total engage value sampled when it is greater than not engage\n",
    "    no = 0  #total not engage value sampled when it is greater than engage\n",
    "    ys = 0  #total times engage was greater\n",
    "    n = 0   #total times not engage was greater\n",
    "\n",
    "    en_flg = 0 #indicates if en reached en_th\n",
    "    want = 0 #if exhaustion is reached, but the subject wanted to engage, this has a value\n",
    "\n",
    "    mn_dec = mn #Can change during a decision\n",
    "    sk_dec = sk #Can change during a decision\n",
    "    intervals = interval(mean_interval,skew_interval,mean_overlap,skew_overlap,mn,sk,ap)\n",
    "\n",
    "    while pos < pos_th and neg < neg_th and en<en_th:\n",
    "        \n",
    "        deliberation = decision_process(mn_dec,sk_dec,ap)\n",
    "\n",
    "        if deliberation[0] == 1:   #engage\n",
    "            pos_change = deliberation_yes(mn_dec,sk_dec,intervals)\n",
    "            mn_dec = pos_change[0]\n",
    "            sk_dec = pos_change[1]\n",
    "            pos +=deliberation[1]\n",
    "            yes+=deliberation[3]\n",
    "            ys+=1 \n",
    "\n",
    "        else: #disengage\n",
    "            neg_change = deliberation_no(mn_dec,sk_dec,intervals)\n",
    "            mn_dec = neg_change[0]\n",
    "            sk_dec = neg_change[1]\n",
    "            neg +=deliberation[1]\n",
    "            no+=deliberation[4]\n",
    "            n+=1\n",
    "\n",
    "        en+=deliberation[2]\n",
    "        rep+=1\n",
    "    \n",
    "    if en>en_th and pos<pos_th and neg<neg_th:\n",
    "        en_flg = 1\n",
    "        if pos>neg:\n",
    "            want = yes/ys\n",
    "    if pos<pos_th:\n",
    "        if n==0:\n",
    "            n = 1\n",
    "            no += deliberation[4]\n",
    "            print('fringe case occured, run again')\n",
    "        \n",
    "    return [1,en,yes/ys,rep,en_flg,want] if pos>pos_th else [0,en,no/n,rep,en_flg,want]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one entire decision\n",
    "#define en and pos before calling\n",
    "def one_decision_CBT(mn,sk,ap,en,pos):\n",
    "    \n",
    "    rep = 0 #number of processes in the decision\n",
    "\n",
    "    \n",
    "    neg = 0 #value of not engaging, if it reaches neg_th the decision is not engage\n",
    "    \n",
    "\n",
    "    yes = 0 #total engage value sampled when it is greater than not engage\n",
    "   \n",
    "    ys = 0  #total times engage was greater\n",
    "    n = 0   #total times not engage was greater\n",
    "\n",
    "    en_flg = 0 #indicates if en reached en_th\n",
    "    want = 0 #if exhaustion is reached, but the subject wanted to engage, this has a value\n",
    "\n",
    "    mn_dec = mn #Can change during a decision\n",
    "    sk_dec = sk #Can change during a decision\n",
    "    intervals = interval(mean_interval,skew_interval,mean_overlap,skew_overlap,mn,sk,ap)\n",
    "\n",
    "    while pos < pos_th and neg < neg_th and en<en_th:\n",
    "        \n",
    "        deliberation = decision_process(mn_dec,sk_dec,ap)\n",
    "\n",
    "        if deliberation[0] == 1:   #engage\n",
    "            pos_change = deliberation_yes(mn_dec,sk_dec,intervals)\n",
    "            mn_dec = pos_change[0]\n",
    "            sk_dec = pos_change[1]\n",
    "            pos +=deliberation[1]\n",
    "            yes+=deliberation[3]\n",
    "            ys+=1 \n",
    "\n",
    "        else: #disengage\n",
    "            neg_change = deliberation_no(mn_dec,sk_dec,intervals)\n",
    "            mn_dec = neg_change[0]\n",
    "            sk_dec = neg_change[1]\n",
    "            neg +=deliberation[1]\n",
    "            \n",
    "            n+=1\n",
    "\n",
    "        en+=deliberation[2]\n",
    "        rep+=1\n",
    "    \n",
    "    if en>en_th and pos<pos_th and neg<neg_th:\n",
    "        en_flg = 1\n",
    "        if pos>neg and ys!=0:\n",
    "            want = yes/ys\n",
    "    \n",
    "        \n",
    "    return [1,en,yes,ys,rep,en_flg,want] if pos>pos_th else [0,en,yes,ys,rep,en_flg,want]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Energy available in a day\n",
    "def day_en_th_fun(x):\n",
    "    return (-176/117*x**2+1058/117*x+100)*1.5/0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#All decisions across d days\n",
    "def day_decisions(ap , days,f_mn,f_sk,f_ap,f_ac,f_en,f_CBT,f_ADM,f_mood,f_disengage,f_CBT_2):\n",
    "\n",
    "    dep = ap/10*0.6 # defines an initial depression score because mood is only generated at the start of the day using dep\n",
    "    \n",
    "     \n",
    "    \n",
    "    #All lists generated for perturbing the model\n",
    "    day_m1,del_m1 = create_lists(f_mn)\n",
    "    day_sk,del_sk = create_lists(f_sk)\n",
    "    day_ap,del_ap = create_lists(f_ap)\n",
    "    day_actual,actual_pos = create_lists(f_ac)\n",
    "    day_energy = create_lists_en(f_en)\n",
    "    day_CBT = create_lists_en(f_CBT)\n",
    "    day_ADM = create_lists_en(f_ADM)\n",
    "    day_mood,mood_cap = create_lists(f_mood)\n",
    "    day_disengage = create_lists_en(f_disengage)\n",
    "    day_CBT_2 = create_lists_en(f_CBT_2)\n",
    "\n",
    "    start = initial(ap,mean_interval,skew_interval,mean_overlap,skew_overlap)\n",
    "    sk = start[1]\n",
    "    \n",
    "    \n",
    "    m1=M1 #allows m1 to change\n",
    "    \n",
    "    no = 0 #total number of not engage decisions\n",
    "    ys = 0 #total engage decisions made across all days\n",
    "    flg = 1 #flag if the current decisions is engage, also used to indicate if the previous decision engaged\n",
    "    en_flg = 0 #total number of exhausts from one decision in a day\n",
    "    day_exhaust = 0 #number of complete exhaustions for a day\n",
    "    \n",
    "    #evolution over all days\n",
    "    ev_mn=[]\n",
    "    ev_sk=[]\n",
    "    ev_ap =[]\n",
    "    ev_pos_dec = []\n",
    "    ev_neg_dec = []\n",
    "    ev_postoneg = []\n",
    "    ev_rep = []\n",
    "    ev_exhaust = []\n",
    "    ev_day_exhaust = []\n",
    "    ev_mood = []\n",
    "    ev_dep = []\n",
    "\n",
    "    for d in range(days):\n",
    "\n",
    "        mood = -1\n",
    "        while mood<0 or mood >1:\n",
    "            mood =  np.random.normal(0.9-dep*0.8,0.1)\n",
    "        md_cap = force_mood(day_mood,mood_cap,d) #forcing a period of low mood\n",
    "        if mood > md_cap: #Cap is 1 when we dont force mood\n",
    "                mood = md_cap\n",
    "        \n",
    "       \n",
    "\n",
    "        \n",
    "        sk = ADM(day_ADM, 50*w, d, sk) #ADM changing the skew, the learning process will deal with this once ADM is stopped\n",
    "        \n",
    "        day_en = 0 #energy used in  a day\n",
    "        dec = 0 # max of 10 decisions in a day\n",
    "        yes = 0  #total engage decisions in a day\n",
    "        day_en_th = day_en_th_fun(ap) \n",
    "\n",
    "        day_en+=force_energy(day_energy,d) #Can add a daily energy usage to force exhaustion\n",
    "        sk+=force_skew(day_sk,del_sk,d) #can force a change in skew\n",
    "        ap+=force_ap(day_ap,del_ap,d) #can force a change in ap\n",
    "        m1+=force_mean(day_m1,del_m1,d) # can fore a change in m1 hence mean\n",
    "        disengage = force_disengage(day_disengage,d) #Force disengagement for a period\n",
    "        cbt_2 = CBT_2(day_CBT_2,d)\n",
    "\n",
    "        while dec<10 and day_en<day_en_th:\n",
    "\n",
    "            mn = mean(dep*10,m1,m2)\n",
    "            if cbt_2 ==1:\n",
    "                \n",
    "                en,pos,outcome,exhaust,loop = 0,0,0,0,0\n",
    "                total_yes=0\n",
    "                total_yes_decs=0\n",
    "                rep = 0\n",
    "                while outcome ==0 and exhaust ==0:\n",
    "                    decision = one_decision_CBT(mn,sk, ap,en,loop*preference)\n",
    "                    outcome = decision[0]\n",
    "                    en+=decision[1]\n",
    "                    total_yes+=decision[2]\n",
    "                    total_yes_decs+=decision[3]\n",
    "                    rep+=decision[4]\n",
    "                    exhaust = decision[5]\n",
    "                    loop+=1\n",
    "                predicted = 0\n",
    "                if total_yes_decs!=0:\n",
    "                    predicted = total_yes/total_yes_decs\n",
    "                want = 0\n",
    "                if decision[6]!=0:\n",
    "                    want = predicted\n",
    "\n",
    "                if outcome==1 and flg ==1:\n",
    "                    flg_con = 1 # two engages in a row\n",
    "                else:\n",
    "                    flg_con = 0\n",
    "                flg = outcome #1 for engage\n",
    "                en_flg+=exhaust  #1 for exhaustion\n",
    "                day_en+=en #energy used by decision\n",
    "                rep = rep # deliberations of a decisions\n",
    "                dec+=1\n",
    "                if flg ==1:\n",
    "                    ys+=1\n",
    "                    yes+=1\n",
    "                elif flg==0:\n",
    "                    no+=1\n",
    "\n",
    "                learn = param_learn(ap,m1,m2,predicted,flg,flg_con,sk,d,day_actual,actual_pos,dep*10,exhaust,want)\n",
    "\n",
    "            elif  disengage ==0: #not forcing disengage\n",
    "                decision = one_decision(mn,sk, ap)\n",
    "                if decision[0]==1 and flg ==1:\n",
    "                    flg_con = 1 # two engages in a row\n",
    "                else:\n",
    "                    flg_con = 0\n",
    "\n",
    "                flg = decision[0] #1 for engage\n",
    "                en_flg+=decision[4]  #1 for exhaustion\n",
    "                day_en+=decision[1] #energy used by decision\n",
    "                rep=decision[3] # deliberations of a decisions\n",
    "                dec+=1\n",
    "\n",
    "                if flg ==1:\n",
    "                    ys+=1\n",
    "                    yes+=1\n",
    "                elif flg==0:\n",
    "                    no+=1\n",
    "\n",
    "                learn = param_learn(ap,m1,m2,decision[2],flg,flg_con,sk,d,day_actual,actual_pos,dep*10,decision[4],decision[5]) # learning process to update m1 (hence mean) skew and apathy\n",
    "            \n",
    "            else: #forcing disengage\n",
    "                \n",
    "                flg_con = 0\n",
    "                flg = 0\n",
    "                rep = 0\n",
    "                dec+=1\n",
    "                no+=1\n",
    "                learn = param_learn(ap,m1,m2,0,flg,flg_con,sk,d,day_actual,actual_pos,dep*10,0,0)\n",
    "            \n",
    "            m1 = learn[0]\n",
    "            \n",
    "            sk+=learn[1]\n",
    "            ap+=learn[2]\n",
    "            mood+=learn[3]/10\n",
    "            \n",
    "            if mood<0:\n",
    "                mood = 0\n",
    "            if mood > md_cap: #Cap is 1 when we dont force mood\n",
    "                mood = md_cap\n",
    "            \n",
    "            if ap<0:\n",
    "                ap = 0\n",
    "            if ap>10:\n",
    "                ap = 10\n",
    "            \n",
    "            ev_mood.append(mood)\n",
    "            ev_mn.append(mn)\n",
    "            ev_sk.append(sk)\n",
    "            ev_ap.append(ap)\n",
    "            ev_pos_dec.append(ys)\n",
    "            ev_neg_dec.append(no)\n",
    "            ev_rep.append(rep)\n",
    "            ev_exhaust.append(en_flg)\n",
    "            \n",
    "            day_en_th = day_en_th_fun(ap) #update daily en_th for new ap\n",
    "           \n",
    "        sk+=learn_sk(yes) #update the skew after each day with the number of engages made in a day\n",
    "\n",
    "        if day_en>=day_en_th: #Ran out of energy in a day\n",
    "\n",
    "            flg = 0\n",
    "            flg_con = 0\n",
    "            day_exhaust+=1\n",
    "\n",
    "            for i in range(10-dec):\n",
    "                #Updating still occurs during complete exhaustion, just the updating of not engaging\n",
    "                mn = mean(dep*10,m1,m2)\n",
    "\n",
    "                learn = param_learn(ap,m1,m2,0,flg,flg_con,sk,d,day_actual,actual_pos,dep*10,1,0) # learning process to update m1 (hence mean) skew and apathy\n",
    "                m1 = learn[0]\n",
    "                sk+=learn[1]\n",
    "                ap+=learn[2]\n",
    "                \n",
    "                if ap<0:\n",
    "                    ap = 0\n",
    "                if ap>10:\n",
    "                    ap = 10\n",
    "               \n",
    "                mood+=learn[3]/10\n",
    "\n",
    "                if mood > md_cap: #Cap is 1 when we dont force mood\n",
    "                    mood = md_cap\n",
    "                if mood<0:\n",
    "                    mood = 0\n",
    "\n",
    "                en_flg+=1 #still counts as a decision made by exhaustion\n",
    "                no+=1\n",
    "\n",
    "                ev_mn.append(mn)\n",
    "                ev_sk.append(sk)\n",
    "                ev_ap.append(ap)\n",
    "                ev_pos_dec.append(ys)\n",
    "                ev_neg_dec.append(no)\n",
    "                ev_exhaust.append(en_flg)\n",
    "                ev_mood.append(mood)\n",
    "\n",
    "        dep = ap/10*(1-0.7)+(1-mood)*0.7  #Dep depends more on low mood than apathy\n",
    "\n",
    "        ev_dep.append(dep)\n",
    "        ev_day_exhaust.append(day_exhaust)\n",
    "        \n",
    "    return [ev_mn,ev_sk,ev_ap,ev_rep,ev_pos_dec,ev_neg_dec, ev_exhaust,ev_day_exhaust,ev_mood,ev_dep]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def mean(ap,m1,m2):\n",
    "    mu = m1-ap*m2\n",
    "    return mu\n",
    "\n",
    "def reward_sens(ap):\n",
    "    return (1-ap/20)\n",
    "\n",
    "def param_learn(ap,m1,m2,val,flg,flg_con,skew,d,day_actual,actual_pos,dep,exhaust,want): #Do I want different learing for exhaustion, should the mean/skew really be updated, apathy should\n",
    "    \n",
    "    del_sk = 0\n",
    "    m1_new = m1\n",
    "\n",
    "    actual = force_actual(day_actual,actual_pos,d) #Forces a value for the actual outcome\n",
    "    if actual == -99: #vaue when we do not force an actual outcome\n",
    "        actual = np.random.normal(M1,var)*reward_sens(ap)\n",
    "    \n",
    "\n",
    "    if flg==1: #engage\n",
    "        dif = (actual-val) #actual*reward sensitivity - predicted\n",
    "        m1_new = m1+w*dif\n",
    "        if dif<0: \n",
    "            del_sk = -1/10*w*36 #if engage is worse than expected skew negatively\n",
    "        \n",
    "            \n",
    "        del_mood = actual\n",
    "    elif exhaust ==1:\n",
    "        if want!=0:\n",
    "            del_mood = np.random.normal(0,var_no) - want\n",
    "        mn = mean(dep,m1,m2)\n",
    "        m, vr, sk, kurt = stats.skewnorm.stats(skew,mn,var, moments='mvsk')\n",
    "        \n",
    "        del_mn = mn - (mn*vr**2)/(var_no**2+vr**2) # multiplication of current and not engage gaussians, without updating var, modified Bayesian Inference\n",
    "        m1_new = m1 - del_mn*w*0.1\n",
    "        del_mood = np.random.normal(0,var_no/2)\n",
    "        if del_mood<=0:\n",
    "            del_sk = 1/10*w*30\n",
    "\n",
    "            \n",
    "\n",
    "    elif flg==0:\n",
    "        mn = mean(dep,m1,m2)\n",
    "        m, vr, sk, kurt = stats.skewnorm.stats(skew,mn,var, moments='mvsk')\n",
    "        \n",
    "        del_mn = mn - (mn*vr**2)/(var_no**2+vr**2) # multiplication of current and not engage gaussians, without updating var, modified Bayesian Inference\n",
    "        m1_new = m1 - del_mn*w\n",
    "        del_mood = np.random.normal(0,var_no)\n",
    "\n",
    "        if del_mood<=0:\n",
    "            del_sk = 1/10*w*30 #Creates a balance between skew and mean\n",
    "        \n",
    "    #If two consecutive engages apathy improves (towards 0), if currently not engaging apathy gets worse, else no change\n",
    "    del_ap = -w*40\n",
    "    if flg_con ==0:\n",
    "        del_ap*=-1 \n",
    "        if flg == 1:\n",
    "            del_ap = 0\n",
    "    \n",
    "\n",
    "    \n",
    "    return(m1_new,del_sk,del_ap,del_mood)\n",
    "\n",
    "def learn_sk(engage):\n",
    "    del_sk = (engage-5)/10*w*40\n",
    "    return(del_sk)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functions to alter the course of the model can be seen as inducing low mood or treating a patient\n",
    "#day will be an array of days when alterations occur\n",
    "#del_* will be the changes which occir on that day\n",
    "#Sequential days will have the same del_*\n",
    "#brakes in sequential days will have value -1, this moves on to the next del_* value\n",
    "\n",
    "def force_mean(day:[],del_m1:[],d):\n",
    "    if day:\n",
    "        if d ==day[-1]:\n",
    "            day.pop()\n",
    "            return del_m1[-1]\n",
    "            \n",
    "        elif day[-1]==-1:\n",
    "            del_m1.pop()\n",
    "            day.pop()\n",
    "        \n",
    "    return 0 \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def force_skew(day:[],del_sk:[],d):\n",
    "    if day:\n",
    "        if d ==day[-1]:\n",
    "            day.pop()\n",
    "            if ADM == True and s >=0:\n",
    "                return 0\n",
    "            return del_sk[-1]\n",
    "            \n",
    "        elif day[-1]==-1:\n",
    "            del_sk.pop()\n",
    "            day.pop()\n",
    "        \n",
    "    return 0 \n",
    "\n",
    "\n",
    "\n",
    "def force_actual(day:[],actual_pos:[],d): #forces a  value for actual positivity of event after engaging\n",
    "\n",
    "    if day:\n",
    "        if d ==day[-1]:\n",
    "            day.pop()\n",
    "            return actual_pos[-1]\n",
    "            \n",
    "        elif day[-1]==-1:\n",
    "            actual_pos.pop()\n",
    "            day.pop()\n",
    "        \n",
    "    return -99\n",
    "\n",
    "\n",
    "\n",
    "def force_energy(day:[],d):  #forces high energy usage to force not engage without affecting distributions\n",
    "    if day:\n",
    "        if d ==day[-1]:\n",
    "            day.pop()\n",
    "            return 1000\n",
    "        \n",
    "    return 0 \n",
    "\n",
    "\n",
    "\n",
    "def force_ap(day:[],del_ap:[],d):\n",
    "\n",
    "    if day:\n",
    "        if d ==day[-1]:\n",
    "            day.pop()\n",
    "            return del_ap[-1]\n",
    "            \n",
    "        elif day[-1]==-1:\n",
    "            del_ap.pop()\n",
    "            day.pop()\n",
    "        \n",
    "    return 0 \n",
    "\n",
    "def force_mood(day:[],mood:[],d): #Force a maximum mood value for a period of days\n",
    "    if day:\n",
    "        if d ==day[-1]:\n",
    "            day.pop()\n",
    "            return mood[-1]\n",
    "            \n",
    "        elif day[-1]==-1:\n",
    "            mood.pop()\n",
    "            day.pop()\n",
    "        \n",
    "    return 1\n",
    "\n",
    "\n",
    "\n",
    "def force_disengage(day:[],d): #Force disengagement for a period of days, set values (deliberation) as NaN and use numpy nanmean, force disengage or loop until disengage is chosen\n",
    "    if day:\n",
    "        if d ==day[-1]:\n",
    "            day.pop()\n",
    "            return 1\n",
    "        \n",
    "    return 0 \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#f is in the format [day,duration,val,day,duration,val...]\n",
    "#day the tool is active, number of days the tool is active, value which the tool changes by\n",
    "# returns an array of active days and their active values\n",
    "\n",
    "def create_lists(f):\n",
    "    if f is None:\n",
    "        return [-2],[-2]\n",
    "    days = []\n",
    "    dels = []\n",
    "    \n",
    "    for i in range(int(len(f)/3)):\n",
    "        start = f[i*3]\n",
    "        duration = f[i*3+1]+1\n",
    "        val=f[i*3+2]\n",
    "        dur = np.arange(start,start+duration,1)\n",
    "        days.extend(dur)\n",
    "        days.append(-1)\n",
    "        dels.append(val)\n",
    "    days.reverse()\n",
    "    dels.reverse()\n",
    "    return days, dels\n",
    "\n",
    "\n",
    "def create_lists_en(f):\n",
    "    if f is None:\n",
    "        return [-2]\n",
    "    days = []\n",
    "    for i in range(int(len(f)/2)):\n",
    "        start = f[i*2]\n",
    "        duration = f[i*2+1]+1\n",
    "        dur = np.arange(start,start+duration,1)\n",
    "        days.extend(dur)\n",
    "    days.reverse()\n",
    "    return days\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#takes the starting apathy, simulton length, days we want to perturb the system and the values they will be perturbed by \n",
    "\n",
    "def Simulation_driver(ap, days,f_mn=None,f_sk=None,f_ap=None,f_ac=None,f_en=None,f_ADM=None,f_CBT=None,f_mood=None,f_disengage=None, f_CBT_2=None):\n",
    "    plt.rcParams[\"figure.figsize\"] = (30, 16)\n",
    "    \n",
    "    fig, axs = plt.subplots(5, 2)\n",
    "    x = np.arange(0,days*10)\n",
    "    x2 = np.arange(0,days)\n",
    "    \n",
    "    for ax in axs.flat:\n",
    "        ax.set(xlabel='decisions', ylabel='value')\n",
    "        ax.ticklabel_format(useOffset=False)\n",
    "    axs[3][1].set(xlabel='days', ylabel='value')\n",
    "    axs[4][1].set(xlabel='days', ylabel='value')\n",
    "    axs[4][0].set(xlabel='days', ylabel='value')\n",
    "\n",
    "    out = day_decisions(ap , days, f_mn,f_sk,f_ap,f_ac,f_en,f_CBT,f_ADM,f_mood,f_disengage, f_CBT_2)\n",
    "    \n",
    "    y1 = out[0]\n",
    "    y2 = out[1]\n",
    "    y3 = out[2]\n",
    "    y4 = out[3]\n",
    "    x4 = np.arange(0,len(y4))\n",
    "    y5 = out[4]\n",
    "    y6 = out[5]\n",
    "    y7 = out[6]\n",
    "    y8 = out[7]\n",
    "    y9 = np.asarray(out[8])\n",
    "    y9_day = np.mean(y9.reshape(-1, 10), axis=1)\n",
    "    y10 = out[9]\n",
    "    print(np.average(y4))\n",
    "    axs[0, 0].plot(x, y1)\n",
    "    axs[0, 0].set_title('evolution of mean')\n",
    "    axs[0, 1].plot(x, y2)\n",
    "    axs[0, 1].set_title('evolution of skew')\n",
    "    axs[1, 0].plot(x, y3)\n",
    "    axs[1, 0].set_title('evolution of apathy')\n",
    "    axs[1, 1].plot(x4, y4)\n",
    "    axs[1, 1].set_title('evolution of deliberation for each decision')\n",
    "    axs[2, 0].plot(x, y5)\n",
    "    axs[2, 0].set_title('evolution of decisions to engage')\n",
    "    axs[2, 1].plot(x, y6)\n",
    "    axs[2, 1].set_title('evolution of decisions to not engage')\n",
    "    axs[3, 0].plot(x, y7)\n",
    "    axs[3, 0].set_title('evolution of exhaustions reached for a decision')\n",
    "    axs[3, 1].plot(x2, y8)\n",
    "    axs[3, 1].set_title('evolution of exhaustions reached for a day')\n",
    "    #axs[4, 0].plot(x, y9)\n",
    "    #axs[4, 0].set_title('evolution of Mood')\n",
    "    axs[4,0].plot(x2, y9_day)\n",
    "    axs[4, 0].set_title('evolution of Mood')\n",
    "    axs[4, 1].plot(x2, y10)\n",
    "    axs[4, 1].set_title('evolution of MDD score')\n",
    "    \n",
    "\n",
    "    fig.tight_layout(pad=5.0)\n",
    "    fig.suptitle('Starting Apathy of {}'.format(ap))\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Day ADM starts on, duration of ADM, value the skew changes by (this might get fixed with research)\n",
    "def ADM(day:[], val ,d , s):\n",
    "    if day:\n",
    "        if d ==day[-1]:\n",
    "            day.pop()\n",
    "            if s>=0.43:\n",
    "                return s\n",
    "            \n",
    "            return s+val\n",
    "            \n",
    "        elif day[-1]==-1:\n",
    "            del_sk.pop()\n",
    "            day.pop()\n",
    "    return s\n",
    "    #Might want something to affect reward sensitivity\n",
    "    #Or have different options depending on the drug of choice\n",
    "    #Could model ADM as a boost to the intial prefrence state, this could wrk with repeated decision making process until we engge\n",
    "\n",
    "\n",
    "\n",
    "def CBT_2(day:[],d):\n",
    "    if day:\n",
    "        if d ==day[-1]:\n",
    "            day.pop()\n",
    "            return 1\n",
    "        elif day[-1]==-1:\n",
    "                day.pop()\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
